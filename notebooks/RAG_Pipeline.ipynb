!pip install langchain sentence-transformers faiss-cpu

# Step 1: Load Documents
from src.data_ingestion import load_documents, split_documents

docs = load_documents("../data/sample_bio_docs/")
print(f"Number of documents loaded: {len(docs)}")

# Step 2: Split Documents into Chunks
chunks = split_documents(docs)
print(f"Number of chunks created: {len(chunks)}")

# Step 3: Display a sample chunk
print("\nSample Chunk:\n")
print(chunks[0].page_content)

# Step 4: Generate Embeddings
from src.embedding_generation import generate_embeddings, create_vectorstore

embedding_model = generate_embeddings()
vectorstore = create_vectorstore(chunks, embedding_model)

print("\nVectorstore created successfully!")
